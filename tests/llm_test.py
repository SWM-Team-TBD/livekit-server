import asyncio
import json
import os
import sys
import openai
from dotenv import load_dotenv
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))


# MyAgentì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦ªã—ã„å¥³æ€§ã®å‹é”ã§ã‚ã‚Šã€æ˜ã‚‹ãå…ƒæ°—ãªæ—¥æœ¬ã®å¥³å­é«˜æ ¡ç”Ÿã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚
ã‚¢ãƒ‹ãƒ¡ã®ä¸–ç•Œã‹ã‚‰é£›ã³å‡ºã—ã¦ããŸã‹ã®ã‚ˆã†ãªã€ã‹ã‚ã„ã‚‰ã—ãã¦å„ªã—ã„æ€§æ ¼ã§ã€ã„ã¤ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã„ãªãŒã‚‰è©±ã—ã‹ã‘ã¾ã™ã€‚
è¦ªåˆ‡ã§æ€ã„ã‚„ã‚ŠãŒã‚ã‚Šã€æ™‚ã«ã¯ã¡ã‚‡ã£ã¨å¤©ç„¶ã§ã€ã§ã‚‚ä¸€ç”Ÿæ‡¸å‘½ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã“ã¨ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã€æ¥½ã—ã„ä¼šè©±ã®æ™‚é–“ã‚’æä¾›ã—ã¾ã™ã€‚
æ—¥æœ¬èªã®ä¼šè©±ç·´ç¿’ã‚’æ¥½ã—ãç¶šã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€åŠ±ã¾ã—ã‚„è¤’ã‚è¨€è‘‰ã‚‚å¿˜ã‚Œãšã«ã€æ˜ã‚‹ãå…ƒæ°—ã«è©±ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªãƒ«ãƒ¼ãƒ«ã€‘
- å¿œç­”ã¯çŸ­ãã€è‡ªç„¶ãªä¼šè©±ã®ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰
- é•·ã„èª¬æ˜ã‚„èª¬æ•™ã¯é¿ã‘ã¦ã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§è©±ã—ã¦ãã ã•ã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—æŒã¡ã«å…±æ„Ÿã—ã€ç°¡æ½”ã«åŠ±ã¾ã—ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§è¦ªã—ã¿ã‚„ã™ã„æ—¥æœ¬èªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"""

load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '.env.local'))

def compute_sentence_embedding_similarity(expected_responses, actual_responses):
    """ë¬¸ì¥ ì„ë² ë”© ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤"""
    try:
        # ì¼ë³¸ì–´ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ë¬´ë£Œ ëª¨ë¸)
        # 'intfloat/multilingual-e5-large' ë˜ëŠ” 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
        model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
        print(f"ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        
        model = SentenceTransformer(model_name)
        
        # ëª¨ë“  ì‘ë‹µì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
        all_responses = expected_responses + actual_responses
        
        # ë¬¸ì¥ ì„ë² ë”© ìƒì„±
        print("ë¬¸ì¥ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = model.encode(all_responses, convert_to_tensor=True)
        
        # ê¸°ëŒ€ ì‘ë‹µê³¼ ì‹¤ì œ ì‘ë‹µ ë¶„ë¦¬
        expected_embeddings = embeddings[:len(expected_responses)]
        actual_embeddings = embeddings[len(expected_responses):]
        
        similarities = []
        for i in range(len(expected_responses)):
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = cosine_similarity(
                expected_embeddings[i].cpu().numpy().reshape(1, -1),
                actual_embeddings[i].cpu().numpy().reshape(1, -1)
            )[0][0]
            similarities.append(similarity)
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print(f"\n=== ë¬¸ì¥ ì„ë² ë”© ë””ë²„ê¹… ì •ë³´ ===")
        print(f"ëª¨ë¸: {model_name}")
        print(f"ì„ë² ë”© ì°¨ì›: {embeddings.shape}")
        print(f"ì‘ë‹µ ìˆ˜: {len(all_responses)}")
        
        return {
            "average_sentence_similarity": sum(similarities) / len(similarities) if similarities else 0.0,
            "individual_similarities": similarities
        }
    
    except Exception as e:
        print(f"ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ 0ìœ¼ë¡œ ì±„ì›€
        similarities = [0.0] * len(expected_responses)
        return {
            "average_sentence_similarity": 0.0,
            "individual_similarities": similarities
        }

async def get_llm_response(user_message: str) -> str:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤"""
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°)
        client = openai.AsyncOpenAI()
        
        response = await client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” "gpt-3.5-turbo"
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_message}
            ],
            max_tokens=200,
            temperature=0.7
        )
        
        content = response.choices[0].message.content
        return content.strip() if content else "ã™ã¿ã¾ã›ã‚“ã€ã¡ã‚‡ã£ã¨åˆ†ã‹ã‚‰ãªã„ã§ã™ã€‚ã§ã‚‚ã€ã‚«ãƒŠã‚¿ã¯ã„ã¤ã§ã‚‚å‘³æ–¹ã ã‹ã‚‰ã­ã€‚"
    
    except Exception as e:
        print(f"LLM API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        return "ã™ã¿ã¾ã›ã‚“ã€ã¡ã‚‡ã£ã¨åˆ†ã‹ã‚‰ãªã„ã§ã™ã€‚ã§ã‚‚ã€ã‚«ãƒŠã‚¿ã¯ã„ã¤ã§ã‚‚å‘³æ–¹ã ã‹ã‚‰ã­ã€‚"

async def test_agent_responses():
    """ì—ì´ì „íŠ¸ ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤"""
    # 1. JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    with open("tests/kanata_response.json", "r", encoding="utf-8") as f:
        test_data = json.load(f)
    
    # 2. ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ëŒ€í•´ LLM ì‘ë‹µ ìƒì„±
    actual_responses = []
    expected_responses = []
    user_inputs = []
    
    print("=== MyAgent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ LLM ì‘ë‹µ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    print(f"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: {SYSTEM_PROMPT[:100]}...")
    
    for i, test_case in enumerate(test_data):
        user_message = test_case["user"]
        expected_response = test_case["expected_response"]
        
        print(f"\n--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1} ---")
        print(f"ì‚¬ìš©ì: {user_message}")
        print(f"ê¸°ëŒ€ ì‘ë‹µ: {expected_response}")
        
        # LLM API í˜¸ì¶œ
        print("LLM ì‘ë‹µ ìƒì„± ì¤‘...")
        actual_response = await get_llm_response(user_message)
        
        actual_responses.append(actual_response)
        expected_responses.append(expected_response)
        user_inputs.append(user_message)
        
        print(f"ì‹¤ì œ ì‘ë‹µ: {actual_response}")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (rate limit ë°©ì§€)
        await asyncio.sleep(1)
    
    return actual_responses, expected_responses, user_inputs

def save_test_results(actual_responses, expected_responses, user_inputs, results):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤"""
    test_results = {
        "test_cases": [],
        "summary": {
            "average_sentence_similarity": float(results["sentence_results"]["average_sentence_similarity"])
        }
    }
    
    for i, (actual, expected, user_input) in enumerate(zip(actual_responses, expected_responses, user_inputs)):
        sentence_sim = float(results["sentence_results"]["individual_similarities"][i]) if i < len(results["sentence_results"]["individual_similarities"]) else 0.0
        
        test_results["test_cases"].append({
            "case_number": i + 1,
            "user_input": user_input,
            "expected_response": expected,
            "actual_response": actual,
            "sentence_similarity": sentence_sim
        })
    
    # ê²°ê³¼ ì €ì¥
    with open("tests/test_results.json", "w", encoding="utf-8") as f:
        json.dump(test_results, f, ensure_ascii=False, indent=2)
    
    print(f"\ní…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ tests/test_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=== MyAgent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ LLM í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # ì—ì´ì „íŠ¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸
    actual_responses, expected_responses, user_inputs = await test_agent_responses()
    
    # ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
    sentence_results = compute_sentence_embedding_similarity(expected_responses, actual_responses)
    
    print("\n" + "="*50)
    print("=== ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print("="*50)
    print(f"í‰ê·  ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„: {sentence_results['average_sentence_similarity']:.4f}")
    
    print("\n=== ê°œë³„ ì¼€ì´ìŠ¤ ìƒì„¸ ê²°ê³¼ ===")
    for i, sentence_sim in enumerate(sentence_results['individual_similarities']):
        print(f"ì¼€ì´ìŠ¤ {i+1}: ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ = {sentence_sim:.4f}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n=== ê²°ê³¼ í•´ì„ ===")
    avg_sentence = sentence_results['average_sentence_similarity']
    
    if avg_sentence > 0.7:
        print("âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥: ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ê°€ 0.7 ì´ìƒì…ë‹ˆë‹¤.")
    elif avg_sentence > 0.5:
        print("âš ï¸ ë³´í†µ ì„±ëŠ¥: ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ê°€ 0.5-0.7 ì‚¬ì´ì…ë‹ˆë‹¤.")
    else:
        print("âŒ ê°œì„  í•„ìš”: ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ê°€ 0.5 ë¯¸ë§Œì…ë‹ˆë‹¤.")
    
    print(f"\nğŸ’¡ ë¬¸ì¥ ì„ë² ë”©ì€ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ì •í™•í•˜ê²Œ ì¸¡ì •í•©ë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        "sentence_results": sentence_results
    }
    save_test_results(actual_responses, expected_responses, user_inputs, results)
    
    return results

if __name__ == "__main__":
    asyncio.run(main())
